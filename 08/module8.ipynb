{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 20:22:47.556717: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-04 20:22:47.557567: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-04 20:22:47.560513: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-04 20:22:47.568690: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-04 20:22:47.584368: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-04 20:22:47.587869: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-04 20:22:47.597505: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-04 20:22:48.226430: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7292526fc9d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[500]/255, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TwoLayerNet in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umd-jrkwon/anaconda3/envs/ece5831-2024/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"sigmoid\", input_shape=(784, )),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"SGD\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need training data!!\n",
    "\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.to_categorical(y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape 28x28 to 784\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize values to 0 .. 1\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test =  keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9078 - loss: 0.3202\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.3089\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9122 - loss: 0.3037\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9165 - loss: 0.2931\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9178 - loss: 0.2892\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9180 - loss: 0.2870\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9181 - loss: 0.2837\n",
      "Epoch 8/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9213 - loss: 0.2763\n",
      "Epoch 9/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9247 - loss: 0.2643\n",
      "Epoch 10/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9242 - loss: 0.2649\n",
      "Epoch 11/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.2607\n",
      "Epoch 12/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9232 - loss: 0.2656\n",
      "Epoch 13/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9281 - loss: 0.2521\n",
      "Epoch 14/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9253 - loss: 0.2585\n",
      "Epoch 15/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.2526\n",
      "Epoch 16/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9299 - loss: 0.2441\n",
      "Epoch 17/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9305 - loss: 0.2423\n",
      "Epoch 18/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9326 - loss: 0.2383\n",
      "Epoch 19/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9331 - loss: 0.2339\n",
      "Epoch 20/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9328 - loss: 0.2352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x78bed87ce530>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 6, 9])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.argmax(y_test[0:10], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions == labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet:\n",
    "    def __init__(self, batch_size=32, epochs=20):\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.model = None\n",
    "        self._create_lenet()\n",
    "        self._compile()\n",
    "    \n",
    "\n",
    "    def _create_lenet(self):\n",
    "        self.model = Sequential([\n",
    "            Conv2D(filters=6, kernel_size=(5,5), \n",
    "                   activation='sigmoid', input_shape=(28, 28, 1), \n",
    "                   padding='same'),\n",
    "            AveragePooling2D(pool_size=(2, 2), strides=2),\n",
    "            \n",
    "            Conv2D(filters=16, kernel_size=(5,5), \n",
    "                   activation='sigmoid', \n",
    "                   padding='same'),\n",
    "            AveragePooling2D(pool_size=(2, 2), strides=2),\n",
    "\n",
    "            Flatten(),\n",
    "\n",
    "            Dense(120, activation='sigmoid'),\n",
    "            Dense(84, activation='sigmoid'),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    def _compile(self):\n",
    "        if self.model is None:\n",
    "            print('Error: Create a model first..')\n",
    "        \n",
    "        self.model.compile(optimizer='Adam',\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "\n",
    "    def _preprocess(self):\n",
    "        # load mnist data\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "        # normalize\n",
    "        x_train = x_train/255.0\n",
    "        x_test = x_test/255.0\n",
    "\n",
    "        # add channel dim\n",
    "        self.x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)  \n",
    "        self.x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)  \n",
    "\n",
    "        # one-hot encoding\n",
    "        self.y_train = to_categorical(y_train, 10)\n",
    "        self.y_test = to_categorical(y_test, 10)\n",
    "\n",
    "    def train(self):\n",
    "        self._preprocess()\n",
    "        self.model.fit(self.x_train, self.y_train, \n",
    "                  batch_size=self.batch_size, \n",
    "                  epochs=self.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umd-jrkwon/anaconda3/envs/ece5831-2024/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "lenet = LeNet(batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.2698 - loss: 1.9674\n",
      "Epoch 2/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.9164 - loss: 0.2832\n",
      "Epoch 3/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.9490 - loss: 0.1708\n",
      "Epoch 4/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.9634 - loss: 0.1216\n",
      "Epoch 5/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9718 - loss: 0.0915\n",
      "Epoch 6/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9748 - loss: 0.0795\n",
      "Epoch 7/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9805 - loss: 0.0628\n",
      "Epoch 8/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9817 - loss: 0.0563\n",
      "Epoch 9/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9842 - loss: 0.0515\n",
      "Epoch 10/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.9866 - loss: 0.0451\n"
     ]
    }
   ],
   "source": [
    "lenet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = np.argmax(lenet.model.predict(x_test[0:10]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.argmax(lenet.y_test[0:10], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "print(predictions == labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece5831-2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
