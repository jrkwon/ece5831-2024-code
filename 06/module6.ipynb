{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_hat, y):\n",
    "    return np.sum((y_hat - y)**2)/y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025000000000000022"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y      = np.array([1,   2,   3,    4])\n",
    "y_hat1 = np.array([1.2, 1.9, 2.9,  4.2]) \n",
    "mean_squared_error(y_hat1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0250000000000004"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat2 = np.array([2.2, 0.9, 2.9,  5.2]) \n",
    "mean_squared_error(y_hat2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y_hat, y):\n",
    "    return -np.sum(y*np.log(y_hat + 1e-7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([0, 1, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat1 = np.array([0.1, 0.7, 0.1, 0.1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3566748010815999"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_error(y_hat1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat2 = np.array([0.7, 0.05, 0.05, 0.2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9957302735559908"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_error(y_hat2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train-images-idx3-ubyte.gz...\n",
      "Done\n",
      "Downloading train-labels-idx1-ubyte.gz...\n",
      "Done\n",
      "Downloading t10k-images-idx3-ubyte.gz...\n",
      "Done\n",
      "Downloading t10k-labels-idx1-ubyte.gz...\n",
      "Done\n",
      "Pickle: dataset/mnist.pkl is being created.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import mnist\n",
    "\n",
    "my_mnist = mnist.Mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (_, _) = my_mnist.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = train_images.shape[0]\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50427 40534 29906 41290  8956 25127 45645 50648 35388 46412  1825 50880\n",
      " 43775 37044 23823 21228 47835 23341 47817 29253 42366 38032 24516   499\n",
      " 17938 40750 43103 46096 17899 49851  8680 25232]\n"
     ]
    }
   ],
   "source": [
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "print(batch_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mini-batch training.\n",
    "def cross_entropy_error(y_hat, y):\n",
    "    batch_size = 1 if y_hat.ndim == 1 else y_hat.shape[0]\n",
    "    return -np.sum(y*np.log(y_hat + 1e-7))/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_batch = np.array([ [0.2, 0.2, 0.3, 0.1, 0.2], [0.1, 0.1, 0.1, 0.1, 0.6]])\n",
    "y_batch =     np.array([ [0,   0,   1,   0,    0],   [0,   0,   0,   0,   1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8573989640459981"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_error(y_hat_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e+48"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.1/10e-50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_diff(f, x):\n",
    "    h = 10e-50\n",
    "    return (f(x + h) - f(x))/h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return x**2 + 0.1*x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(func, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more reasonable approximation\n",
    "def numerical_diff(f, x):\n",
    "    h = 1e-4\n",
    "    return (f(x + h) - f(x - h))/(2*h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6999999999994797"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(func, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49999999999994493"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(func, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "\n",
    "def func_tmp1(x0):\n",
    "    return x0**2 + 4.0**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.00000000000378"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(func_tmp1, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_tmp2(x1):\n",
    "    return 3.0**2 + x1**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.999999999999119"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(func_tmp2, 4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func2(x):\n",
    "    return x[0]**2 + x[1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial derivatives when x0 = 3, x1 = 4\n",
    "\n",
    "def func_tmp1(x0):\n",
    "    return x0**2 + 4**2\n",
    "\n",
    "def func_tmp2(x1):\n",
    "    return 3**2 + x1**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _numerical_diff(f, x):\n",
    "    h = 1e-4\n",
    "    return (f(x + h) - f(x - h))/(2*h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _numerical_gradient(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x) \n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        \n",
    "        # f(x+h) \n",
    "        x[idx] = float(tmp_val) + h\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        # f(x-h) \n",
    "        x[idx] = tmp_val - h \n",
    "        fxh2 = f(x) \n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        x[idx] = tmp_val \n",
    "        \n",
    "    return grad\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.00000000000378"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_numerical_diff(func_tmp1, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.999999999999119"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_numerical_diff(func_tmp2, 4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 8.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_numerical_gradient(func2, np.array([3.0, 4.0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(f, init_x, lr=0.1, step_num = 100):\n",
    "    x = init_x\n",
    "    for i in range(step_num):\n",
    "        grad = _numerical_gradient(f, x)\n",
    "        x -= lr*grad  # x = x - lr*grad\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.65680105e-06, 2.02028609e-06])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_x = np.array([2800.0, 1000.0])\n",
    "# func2 = x0**2 + x1**2\n",
    "gradient_descent(func2, init_x, step_num=10000, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet:\n",
    "    def __init__(self):\n",
    "        self.w = np.random.randn(2, 3)\n",
    "\n",
    "\n",
    "    # for multi-dimensional x\n",
    "    def softmax(self, x):\n",
    "        if x.ndim == 2:\n",
    "            x = x.T\n",
    "            x = x - np.max(x, axis=0)\n",
    "            y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "            return y.T \n",
    "\n",
    "        x = x - np.max(x)  \n",
    "        return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "\n",
    "    def cross_entroy_error(self, y, t):\n",
    "        delta = 1e-7\n",
    "        batch_size = 1 if y.ndim == 1 else y.shape[0]\n",
    "\n",
    "        return -np.sum(t*np.log(y + delta)) / batch_size\n",
    "\n",
    "\n",
    "    # for multi-dimensional x\n",
    "    def numerical_gradient(self, f, x):\n",
    "        h = 1e-4 # 0.0001\n",
    "        grad = np.zeros_like(x)\n",
    "        \n",
    "        it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "        while not it.finished:\n",
    "            idx = it.multi_index\n",
    "            tmp_val = x[idx]\n",
    "            x[idx] = float(tmp_val) + h\n",
    "            fxh1 = f(x) # f(x+h)\n",
    "            \n",
    "            x[idx] = tmp_val - h \n",
    "            fxh2 = f(x) # f(x-h)\n",
    "            grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "            \n",
    "            x[idx] = tmp_val \n",
    "            it.iternext()   \n",
    "            \n",
    "        return grad\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.w)\n",
    "    \n",
    "\n",
    "    def loss(self, x, y):\n",
    "        z = self.predict(x)\n",
    "        y_hat = self.softmax(z)\n",
    "        loss = self.cross_entroy_error(y_hat, y)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.68927577 -1.11643295 -0.13601282]\n",
      " [ 0.60219774  0.58673274 -1.60266364]]\n"
     ]
    }
   ],
   "source": [
    "# let's test SimpleNet\n",
    "net = SimpleNet()\n",
    "print(net.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.16565823e-01  6.67160157e-01  3.27396510e-04]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([0.7, 0.19])\n",
    "p = net.predict(x)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6780501115099065"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([0, 1, 0])\n",
    "net.loss(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3448826849923987"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([0, 0, 1])\n",
    "net.loss(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(w):\n",
    "    return net.loss(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.42403234  0.1194473  -0.54347965]\n",
      " [ 0.11509449  0.03242141 -0.1475159 ]]\n"
     ]
    }
   ],
   "source": [
    "dw = net.numerical_gradient(loss_function, net.w)\n",
    "print(dw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using lamda\n",
    "loss_function = lambda w: net.loss(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.42403234  0.1194473  -0.54347965]\n",
      " [ 0.11509449  0.03242141 -0.1475159 ]]\n"
     ]
    }
   ],
   "source": [
    "dw = net.numerical_gradient(loss_function, net.w)\n",
    "print(dw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TwoLayerNet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activations:\n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1 + np.exp(-x))\n",
    "    \n",
    "    # for multi-dimensional x\n",
    "    def softmax(self, x):\n",
    "        if x.ndim == 2:\n",
    "            x = x.T\n",
    "            x = x - np.max(x, axis=0)\n",
    "            y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "            return y.T \n",
    "\n",
    "        x = x - np.max(x)  \n",
    "        return np.exp(x) / np.sum(np.exp(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Errors:\n",
    "    def cross_entroy_error(self, y, t):\n",
    "        delta = 1e-7\n",
    "        batch_size = 1 if y.ndim == 1 else y.shape[0]\n",
    "\n",
    "        return -np.sum(t*np.log(y + delta)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import activations\n",
    "import errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        self.params = {}\n",
    "\n",
    "        self.params['w1'] = weight_init_std*np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "\n",
    "        self.params['w2'] = weight_init_std*np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "        self.activations = activations.Activations()\n",
    "        self.errors = errors.Errors()\n",
    "\n",
    "    def predict(self, x):\n",
    "        w1, w2 = self.params['w1'], self.params['w2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        \n",
    "        a1 = np.dot(x, w1) + b1\n",
    "        z1 = self.activations.sigmoid(a1)\n",
    "        a2 = np.dot(z1, w2) + b2\n",
    "        y = self.activations.softmax(a2)\n",
    "\n",
    "        return y\n",
    "    \n",
    "    def loss(self, x, y):\n",
    "        y_hat = self.predict(x)\n",
    "\n",
    "        return self.errors.cross_entropy_error(y_hat, y)\n",
    "    \n",
    "\n",
    "    def accuracy(self, x, y):\n",
    "        y_hat = self.predict(x)\n",
    "        p = np.argmax(y_hat, axis=1)\n",
    "        y_p = np.argmax(y, axis=1)\n",
    "\n",
    "        return np.sum(p == y_p)/float(x.shape[0])\n",
    "    \n",
    "\n",
    "    # for multi-dimensional x\n",
    "    def _numerical_gradient(self, f, x):\n",
    "        h = 1e-4 # 0.0001\n",
    "        grad = np.zeros_like(x)\n",
    "        \n",
    "        it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "        while not it.finished:\n",
    "            idx = it.multi_index\n",
    "            tmp_val = x[idx]\n",
    "            x[idx] = float(tmp_val) + h\n",
    "            fxh1 = f(x) # f(x+h)\n",
    "            \n",
    "            x[idx] = tmp_val - h \n",
    "            fxh2 = f(x) # f(x-h)\n",
    "            grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "            \n",
    "            x[idx] = tmp_val \n",
    "            it.iternext()   \n",
    "            \n",
    "        return grad\n",
    "    \n",
    "\n",
    "    def numerical_gradient(self, x, y):\n",
    "        loss_w = lambda w: self.loss(x, y)\n",
    "\n",
    "        grads = {}\n",
    "        grads['w1'] = self._numerical_gradient(loss_w, self.params['w1'])\n",
    "        grads['b1'] = self._numerical_gradient(loss_w, self.params['b1'])\n",
    "        grads['w2'] = self._numerical_gradient(loss_w, self.params['w2'])\n",
    "        grads['b2'] = self._numerical_gradient(loss_w, self.params['b2'])\n",
    "\n",
    "        return grads\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train TwoLayerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: train-images-idx3-ubyte.gz already exists.\n",
      "File: train-labels-idx1-ubyte.gz already exists.\n",
      "File: t10k-images-idx3-ubyte.gz already exists.\n",
      "File: t10k-labels-idx1-ubyte.gz already exists.\n",
      "Pickle: dataset/mnist.pkl already exists.\n",
      "Loading...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "my_mnist = mnist.Mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = my_mnist.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "network = TwoLayerNet(input_size=28*28, hidden_size=100, output_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'w1': array([[ 0.00691821, -0.00766628,  0.0011048 , ..., -0.01444509,\n",
       "         -0.02096234, -0.00539125],\n",
       "        [ 0.02158764, -0.00461593, -0.01653164, ..., -0.01917657,\n",
       "          0.00191896, -0.00962898],\n",
       "        [ 0.00196323, -0.00159347, -0.02317298, ...,  0.00037187,\n",
       "         -0.00677226, -0.00200744],\n",
       "        ...,\n",
       "        [-0.00456412, -0.01142783,  0.00240188, ...,  0.01069273,\n",
       "         -0.01019897, -0.00378351],\n",
       "        [ 0.00144244,  0.01231268,  0.00395283, ..., -0.0180285 ,\n",
       "         -0.00639699, -0.00790048],\n",
       "        [-0.01467352, -0.00049144, -0.01761132, ...,  0.00548518,\n",
       "          0.01314084,  0.00341427]]),\n",
       " 'b1': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'w2': array([[-8.29861325e-03,  1.30006217e-02, -7.58354272e-03,\n",
       "          4.33822642e-05,  5.04783190e-03, -1.54405148e-02,\n",
       "         -1.14032437e-02, -2.31073862e-03, -5.26458929e-03,\n",
       "         -9.61259532e-03],\n",
       "        [ 2.24037718e-02, -2.98240150e-03,  6.79530231e-03,\n",
       "          1.69841104e-03, -1.28829723e-03, -5.94962673e-03,\n",
       "         -2.26922673e-04,  1.15593230e-03, -1.49984809e-02,\n",
       "         -9.27642412e-04],\n",
       "        [-2.07428860e-02, -7.50477921e-03, -2.63611881e-02,\n",
       "         -2.50577191e-03,  5.31995868e-03,  1.10166974e-02,\n",
       "          6.26901106e-03, -8.52061443e-03,  1.54796959e-02,\n",
       "          4.98446088e-04],\n",
       "        [ 1.38282105e-02, -3.64997435e-03,  1.26178580e-02,\n",
       "          6.29914931e-03, -1.57184637e-02,  9.57097081e-03,\n",
       "          7.85605032e-03, -1.00689260e-02, -1.17276721e-02,\n",
       "         -1.42364272e-02],\n",
       "        [-7.62278008e-03, -1.17477499e-03,  1.82859567e-02,\n",
       "         -3.43898643e-03, -7.88718355e-03, -8.60816546e-03,\n",
       "         -1.87215528e-02, -8.67961730e-04, -1.38204043e-02,\n",
       "         -6.57147112e-04],\n",
       "        [-2.71733977e-03, -7.06802794e-03,  2.00013571e-03,\n",
       "          2.17013970e-02, -1.39873891e-02, -1.72888477e-02,\n",
       "          1.17702587e-02,  2.80656203e-03, -1.67570569e-02,\n",
       "          1.86552193e-02],\n",
       "        [-5.59816876e-03, -3.75255309e-03, -8.04856925e-03,\n",
       "         -7.95341442e-03,  3.77791458e-03, -9.19222905e-04,\n",
       "          1.17036924e-02,  2.21255377e-02, -1.32633263e-02,\n",
       "          8.73391065e-04],\n",
       "        [ 3.90915524e-03,  7.79617651e-04, -1.30910089e-02,\n",
       "         -3.65860982e-03, -2.29589570e-02,  9.11469042e-03,\n",
       "         -3.45370387e-03, -9.37620845e-03, -5.20340221e-03,\n",
       "         -2.18163997e-03],\n",
       "        [ 1.25070821e-02, -1.07086398e-02, -1.03897773e-02,\n",
       "         -8.51013503e-03,  5.67280681e-03,  1.07822542e-04,\n",
       "          5.09744711e-03,  1.69837243e-02,  8.11415905e-03,\n",
       "          1.14025659e-02],\n",
       "        [ 2.15669992e-03, -1.15000779e-03,  1.00490477e-02,\n",
       "          1.32278768e-02,  9.22858470e-04, -8.67481354e-03,\n",
       "          1.63252796e-02, -3.14196652e-03,  1.66585306e-02,\n",
       "          2.37592908e-03],\n",
       "        [-2.92767763e-03,  1.08197088e-02, -2.91472957e-03,\n",
       "         -2.04533873e-02,  4.02410664e-04, -7.99978372e-03,\n",
       "         -3.24705836e-02, -1.20214279e-02,  8.20202352e-03,\n",
       "         -8.12386613e-03],\n",
       "        [ 2.54079953e-03, -4.08047981e-03, -2.80340445e-03,\n",
       "          5.60370967e-03,  3.79908011e-03,  1.53908795e-02,\n",
       "          8.73793521e-03,  3.78629396e-03,  1.91247364e-03,\n",
       "          3.09597672e-03],\n",
       "        [-1.30152939e-02,  1.20072693e-04, -1.53527289e-02,\n",
       "         -2.94921096e-03,  6.16761335e-03, -5.57336338e-03,\n",
       "         -1.80787314e-03,  1.31553973e-02, -1.16247780e-03,\n",
       "          1.53379317e-02],\n",
       "        [-5.50148227e-03,  1.04410571e-02, -2.13532155e-02,\n",
       "         -8.74903300e-03,  6.16721779e-03, -2.62890156e-03,\n",
       "         -3.22618437e-04,  4.18816567e-04,  5.66823912e-03,\n",
       "          1.50536872e-02],\n",
       "        [ 9.37879104e-03,  2.12155147e-02, -1.64375374e-02,\n",
       "         -3.65462444e-03,  1.83770222e-02,  9.25493599e-04,\n",
       "          9.68487922e-03,  4.79910218e-03,  9.49236548e-03,\n",
       "         -1.53545261e-04],\n",
       "        [ 7.16031191e-03,  1.03231002e-02, -3.18896705e-03,\n",
       "         -2.98442726e-03,  5.37128235e-03,  3.00454914e-03,\n",
       "         -2.90186678e-02, -8.60797875e-04,  4.33775760e-03,\n",
       "         -2.48421804e-03],\n",
       "        [-8.94388494e-03,  1.15532419e-02, -6.50962088e-03,\n",
       "          4.11082899e-03,  8.37736292e-03,  1.41071222e-02,\n",
       "         -1.04148490e-03, -1.48605333e-03, -2.12511659e-04,\n",
       "          1.11405617e-02],\n",
       "        [ 7.26079814e-03, -9.30597635e-03, -3.01832998e-04,\n",
       "         -2.01598631e-02,  5.70192653e-03, -4.61497134e-04,\n",
       "         -1.19870878e-02, -1.10290880e-02, -8.80863847e-03,\n",
       "          6.54746173e-03],\n",
       "        [ 7.27183886e-03,  1.22940119e-03,  6.48282197e-03,\n",
       "         -5.80902249e-03,  1.49400597e-02,  1.09174014e-02,\n",
       "         -3.67113311e-03, -2.01961610e-03, -2.65025974e-02,\n",
       "         -2.36367608e-03],\n",
       "        [-9.24158084e-03, -1.99155569e-02, -1.80341636e-03,\n",
       "         -1.03450720e-02,  1.02864233e-02,  1.83531099e-02,\n",
       "         -1.22676522e-02,  2.71940173e-04, -6.48377748e-03,\n",
       "         -3.41121745e-03],\n",
       "        [-1.00782048e-02, -3.97596461e-03,  2.86590418e-03,\n",
       "         -2.25645437e-03,  9.49947355e-03, -2.49815647e-03,\n",
       "          5.04357209e-03, -4.55638689e-03, -3.53313253e-03,\n",
       "          8.66822484e-04],\n",
       "        [ 7.99756938e-03, -5.90037812e-03, -1.67595910e-02,\n",
       "         -1.71222611e-02,  1.71176886e-02,  1.81963757e-02,\n",
       "         -1.44096295e-02, -5.87824564e-03,  5.15225943e-03,\n",
       "          2.43093646e-02],\n",
       "        [ 6.11581546e-03, -5.38385163e-04,  1.18616724e-02,\n",
       "          2.69116413e-04, -1.15218988e-02, -6.76009832e-03,\n",
       "         -1.97663687e-03,  1.62289188e-02,  4.73235434e-04,\n",
       "          1.35649300e-03],\n",
       "        [-1.22032969e-03,  4.80696980e-03,  1.58695073e-02,\n",
       "         -4.44326407e-03,  1.09970300e-02, -9.20747145e-03,\n",
       "          8.14374814e-03,  2.89180239e-03, -7.35892646e-04,\n",
       "          9.98882113e-03],\n",
       "        [-1.72181238e-02, -5.98915593e-03,  1.20473588e-03,\n",
       "          1.04006316e-02,  1.89315253e-03, -5.74499168e-03,\n",
       "          1.95690214e-02, -6.88492369e-03,  7.51565479e-04,\n",
       "          2.65177356e-03],\n",
       "        [ 8.78368989e-03,  5.62042587e-03,  4.79134785e-03,\n",
       "         -1.06981570e-02,  1.14836946e-03, -2.86393637e-03,\n",
       "         -4.92496103e-03,  5.44144729e-03,  1.10760317e-02,\n",
       "         -1.45992102e-02],\n",
       "        [ 8.91928066e-03, -2.70316527e-02, -1.35634269e-02,\n",
       "         -3.55231802e-03, -7.54673496e-03, -1.07369813e-02,\n",
       "          3.42206516e-03,  1.32957640e-02, -1.13985340e-02,\n",
       "          1.90830438e-02],\n",
       "        [-8.72997119e-03, -5.18446801e-03, -4.81124587e-05,\n",
       "          2.01280187e-02,  1.90233500e-03, -2.77552200e-04,\n",
       "         -1.04521151e-02, -9.88282213e-03, -1.03223977e-02,\n",
       "         -4.40287848e-03],\n",
       "        [-1.24682262e-03,  1.19746993e-02, -1.31450490e-02,\n",
       "          1.68106378e-03, -5.24744378e-03,  6.42824230e-03,\n",
       "          2.12596582e-03, -2.31322224e-03, -1.21567440e-03,\n",
       "         -1.53236658e-03],\n",
       "        [ 2.17202910e-03, -1.31389667e-02, -1.21883704e-02,\n",
       "          2.03038557e-03,  3.61384670e-04, -6.40114897e-03,\n",
       "          2.64263314e-02,  1.34625725e-02,  9.35821972e-03,\n",
       "          9.59688592e-03],\n",
       "        [-8.63840654e-03,  4.72395282e-03, -4.93661125e-04,\n",
       "         -2.15973365e-03, -2.46960848e-03,  9.13737938e-03,\n",
       "         -1.55292283e-02,  5.57439347e-04, -1.41926854e-03,\n",
       "         -6.04654997e-06],\n",
       "        [ 4.30227267e-03, -8.14674301e-03,  7.71848408e-03,\n",
       "          1.91071666e-02,  1.24514450e-02,  4.28281502e-03,\n",
       "          6.11444910e-03, -4.12768503e-03,  1.29380068e-02,\n",
       "          9.35307321e-03],\n",
       "        [ 1.74827074e-02, -6.69406580e-03, -7.91543905e-03,\n",
       "          7.85132378e-03, -4.01659256e-03, -5.96625157e-03,\n",
       "         -5.77325815e-03, -3.52014983e-03,  2.42387236e-03,\n",
       "          8.24553795e-04],\n",
       "        [ 3.09660911e-03,  8.44697242e-03, -1.78162453e-02,\n",
       "         -6.88095899e-03, -8.26978573e-03, -3.45787916e-03,\n",
       "          2.42243141e-03, -1.14464348e-02, -6.94101689e-03,\n",
       "          1.69575550e-02],\n",
       "        [ 4.26900254e-03,  1.51927549e-02,  3.48161282e-03,\n",
       "          2.49819445e-03,  9.68577057e-03,  3.99859082e-03,\n",
       "          9.88075133e-03, -1.50207266e-02,  1.20773446e-02,\n",
       "         -6.89106267e-03],\n",
       "        [-1.71414213e-02,  1.25153672e-02,  1.65385490e-02,\n",
       "          3.96471138e-04,  1.45486251e-03, -1.06501595e-02,\n",
       "          6.75294302e-03,  1.36635089e-03,  1.69981394e-02,\n",
       "          1.44241587e-02],\n",
       "        [-3.32156026e-03,  3.46576202e-03, -1.95565555e-02,\n",
       "          7.31308998e-03,  1.01216433e-02, -1.76955855e-03,\n",
       "          4.33328704e-03,  1.35337088e-02, -2.89712385e-03,\n",
       "          1.38969720e-03],\n",
       "        [-7.59192718e-03, -1.15486774e-02,  1.47838476e-02,\n",
       "         -7.06180448e-03, -1.18316963e-02,  1.26623590e-02,\n",
       "          7.11063298e-03,  5.83853849e-03,  2.11955979e-03,\n",
       "         -1.19752622e-02],\n",
       "        [-4.82157967e-03, -4.52706379e-03,  1.00180288e-02,\n",
       "          1.43793279e-02, -6.63220593e-03,  3.69569737e-03,\n",
       "          1.88278992e-02, -6.88174402e-03,  9.05308411e-03,\n",
       "         -5.33341397e-04],\n",
       "        [-2.45176218e-03, -1.18655085e-02,  1.19911878e-02,\n",
       "         -8.90958906e-03, -3.31441235e-03,  1.71006327e-02,\n",
       "         -1.81967458e-03,  1.72052463e-03, -5.70120255e-03,\n",
       "          1.33654572e-02],\n",
       "        [ 3.87735682e-03,  8.21660012e-03, -8.53744587e-03,\n",
       "          1.09584255e-02,  8.37415217e-03,  2.29784328e-03,\n",
       "          1.51668365e-02, -9.98081345e-03,  1.21124514e-02,\n",
       "          4.84765088e-03],\n",
       "        [-7.54900778e-03,  3.31099724e-04, -3.93226640e-03,\n",
       "         -5.47998685e-03,  7.04286263e-03, -2.96153208e-03,\n",
       "          1.20422594e-02, -1.33428409e-03,  1.91563878e-02,\n",
       "         -9.58335547e-03],\n",
       "        [-9.53328205e-03,  1.45262872e-02, -1.82081681e-02,\n",
       "          1.36454015e-03, -6.99785663e-03,  2.46431840e-02,\n",
       "          5.68392031e-05,  9.22484742e-03, -3.61122849e-03,\n",
       "          4.69923999e-03],\n",
       "        [-3.54430596e-03,  1.96040318e-02,  2.90619858e-03,\n",
       "         -1.92889754e-02,  8.72266970e-03, -4.84654120e-03,\n",
       "          4.66435397e-03, -2.60961881e-03, -2.45178723e-03,\n",
       "          2.71147874e-02],\n",
       "        [-1.01714235e-02,  1.82258897e-02, -6.93304064e-03,\n",
       "         -8.46193962e-03, -5.54457740e-03,  1.71767068e-02,\n",
       "          6.02296617e-03, -9.45159669e-03,  1.48528554e-02,\n",
       "          1.27057197e-02],\n",
       "        [-1.44095481e-02,  1.54533054e-02,  9.69685473e-03,\n",
       "         -3.48736383e-03,  2.37189886e-03, -3.72790735e-03,\n",
       "          4.20488373e-03,  9.54063863e-03,  6.30357991e-03,\n",
       "          7.92997196e-03],\n",
       "        [ 3.69284882e-03, -1.94869305e-03,  9.06635966e-03,\n",
       "          1.16753032e-03,  1.95359128e-03,  5.77073759e-03,\n",
       "          5.25902365e-03,  1.42460822e-02, -1.06975632e-02,\n",
       "         -1.27706235e-02],\n",
       "        [ 1.03550554e-02,  4.41965118e-03, -5.61828203e-03,\n",
       "          1.25954798e-02, -1.28664536e-02, -9.68796599e-03,\n",
       "          8.09570386e-03,  1.06171319e-02, -4.92734866e-03,\n",
       "         -1.47122790e-02],\n",
       "        [-3.45174292e-03, -8.90803695e-03, -4.95273701e-03,\n",
       "          2.01734989e-02, -7.73192819e-03, -9.93544219e-03,\n",
       "          9.35211728e-03,  5.77416249e-03,  2.62592647e-03,\n",
       "          3.33301297e-03],\n",
       "        [ 2.62556816e-02,  5.14378860e-03, -3.50385390e-03,\n",
       "         -2.44447413e-02,  1.51712980e-03, -1.71442530e-02,\n",
       "          5.17842494e-04, -9.24320785e-03,  5.39626578e-03,\n",
       "         -2.44714580e-03],\n",
       "        [ 1.33347347e-02, -3.07313435e-03, -7.31304784e-03,\n",
       "          1.54573664e-03,  1.92888092e-02, -4.75142000e-03,\n",
       "          1.29809873e-02, -2.97776270e-03,  8.15627164e-03,\n",
       "          4.59788030e-03],\n",
       "        [ 1.90647149e-02, -9.35588673e-03, -2.21278850e-03,\n",
       "         -7.19861207e-03, -1.14438193e-03,  4.84354680e-03,\n",
       "         -1.68671254e-03,  1.23202569e-02, -7.12850064e-03,\n",
       "          7.77591717e-04],\n",
       "        [-7.00008572e-03,  2.10122116e-02,  1.03736633e-02,\n",
       "         -1.05611369e-02,  6.17781632e-03, -2.27953662e-02,\n",
       "         -9.28884881e-03, -8.91153854e-03,  3.73526487e-03,\n",
       "          8.61848147e-03],\n",
       "        [-2.87577642e-04, -1.34328371e-02, -7.19956051e-03,\n",
       "         -3.76762403e-03, -5.91104897e-04, -4.17255008e-03,\n",
       "         -1.18208295e-02, -2.12761472e-03, -2.67472824e-03,\n",
       "         -1.98790973e-03],\n",
       "        [-2.52707096e-03, -4.70657145e-03, -4.70458849e-03,\n",
       "          5.70567546e-03, -7.75254098e-03, -1.77865014e-02,\n",
       "         -4.72145695e-03, -1.99647691e-03,  9.73271632e-03,\n",
       "          1.08072238e-02],\n",
       "        [ 7.83797879e-03, -3.72301018e-03,  1.85230918e-02,\n",
       "          5.39199990e-03, -3.57372204e-03,  3.63774370e-03,\n",
       "          1.40771442e-02,  2.21951165e-03,  4.21707223e-03,\n",
       "         -1.11305702e-02],\n",
       "        [ 4.75525315e-03, -7.52378764e-03,  6.26335559e-03,\n",
       "          2.59305977e-03, -5.46498436e-03, -7.50387066e-03,\n",
       "          3.54410842e-03, -1.41039590e-02,  1.47398257e-02,\n",
       "         -2.08841006e-03],\n",
       "        [ 3.95430707e-03,  5.01159785e-03,  6.85397144e-04,\n",
       "          4.07637237e-03,  4.03142690e-03, -2.10773150e-02,\n",
       "         -1.23810475e-02,  1.85733493e-03, -1.02517464e-02,\n",
       "          5.31302201e-03],\n",
       "        [-1.50602987e-02, -1.32390964e-02, -8.81313526e-03,\n",
       "         -1.86647548e-02,  1.58876724e-02,  3.08485041e-02,\n",
       "          4.66165053e-03, -1.05795345e-02,  7.30296833e-03,\n",
       "          2.75598670e-03],\n",
       "        [ 8.99054377e-03,  1.96534652e-02, -1.52755495e-02,\n",
       "          3.68857937e-03,  1.12613349e-03,  3.40862351e-03,\n",
       "          4.39217820e-03, -6.53383399e-04, -6.48685178e-03,\n",
       "          7.38488161e-03],\n",
       "        [ 1.22202744e-04,  6.56728994e-03, -3.16977483e-03,\n",
       "          1.54199412e-02, -9.37310292e-03, -4.32250612e-03,\n",
       "         -1.80440967e-03,  1.07558545e-02, -9.87987614e-03,\n",
       "          1.89898127e-02],\n",
       "        [-1.31592835e-02, -6.45610707e-03, -3.09640443e-03,\n",
       "         -9.02593205e-04,  2.24865052e-02, -1.77686565e-03,\n",
       "          7.41462959e-03, -1.18360701e-02, -1.11277267e-02,\n",
       "          1.08270147e-02],\n",
       "        [ 7.24063710e-03,  1.32446199e-03,  9.98052330e-03,\n",
       "          1.10926183e-02,  1.11823027e-03, -5.96144216e-03,\n",
       "         -5.00756374e-03,  1.70484449e-03,  9.56437783e-03,\n",
       "         -3.31455419e-03],\n",
       "        [ 2.21354238e-03, -1.47341180e-02,  9.35769312e-04,\n",
       "          6.04144973e-03, -1.25735524e-04,  1.62680037e-02,\n",
       "         -8.12542396e-03, -4.60642617e-03,  8.18297417e-03,\n",
       "         -5.30317250e-03],\n",
       "        [ 4.71172782e-03, -5.52724340e-04, -4.44257315e-03,\n",
       "          9.01778983e-03, -2.86923315e-03,  9.91355006e-03,\n",
       "         -2.10685720e-03, -1.07474821e-02,  1.07767657e-03,\n",
       "          1.42125708e-02],\n",
       "        [ 4.05283411e-03,  5.75719883e-03, -1.63878823e-02,\n",
       "         -5.48572636e-03, -1.11966762e-02,  1.27768272e-02,\n",
       "          9.84199831e-04, -4.68613942e-03,  1.95922149e-03,\n",
       "         -8.82326573e-03],\n",
       "        [-5.16048854e-03,  9.77370832e-03, -8.81399422e-03,\n",
       "          1.22634924e-02,  3.76201483e-03, -8.48138227e-03,\n",
       "          4.50315485e-04, -7.20338916e-04, -3.29364339e-04,\n",
       "         -1.14768566e-02],\n",
       "        [-6.07889705e-04,  2.97086086e-03,  8.75733013e-03,\n",
       "         -1.00897549e-02,  5.27167808e-03,  9.35233156e-03,\n",
       "         -4.19220130e-03, -5.77399672e-04,  2.46464660e-03,\n",
       "          3.60095749e-03],\n",
       "        [ 9.41454440e-03, -8.26766099e-04,  7.21762902e-03,\n",
       "         -9.11992100e-03,  4.55514035e-04, -1.16004688e-02,\n",
       "          5.51699421e-03,  5.03661065e-03,  6.61545346e-04,\n",
       "          5.53023738e-03],\n",
       "        [ 7.51294986e-04,  2.91848581e-03,  9.94471300e-03,\n",
       "         -7.95388856e-03,  6.04333789e-03,  5.03281239e-04,\n",
       "         -3.74164256e-03, -4.19805757e-05, -1.24578364e-02,\n",
       "          2.52393669e-02],\n",
       "        [ 5.00598414e-03,  2.84651597e-03,  1.79040387e-02,\n",
       "         -1.23305111e-02,  2.07931456e-03, -1.88664875e-03,\n",
       "         -7.89334484e-03,  7.42395832e-03,  9.87641481e-03,\n",
       "          6.12053517e-03],\n",
       "        [-2.77655110e-03, -1.73080420e-02,  8.99360468e-03,\n",
       "          4.24485821e-03, -3.45491502e-03, -1.80295322e-03,\n",
       "         -5.75238772e-05,  2.39016840e-03, -1.84815805e-02,\n",
       "         -2.65778765e-02],\n",
       "        [-2.61108954e-03,  6.59406122e-03, -8.06595198e-03,\n",
       "          6.89197666e-03,  7.65521035e-03, -1.03211160e-02,\n",
       "         -2.45247562e-03, -1.12841456e-02, -3.65706409e-03,\n",
       "          9.64202815e-03],\n",
       "        [ 8.71414921e-03,  3.00798975e-03,  1.00330639e-02,\n",
       "         -3.40052547e-04,  1.84228528e-02,  6.80792970e-03,\n",
       "         -2.38126736e-03,  4.41901239e-03, -2.12528611e-02,\n",
       "         -6.33608778e-03],\n",
       "        [ 1.64301589e-02,  1.12947643e-02, -1.17868835e-02,\n",
       "         -9.52661084e-03, -4.62630697e-04,  3.50126142e-03,\n",
       "          8.83047589e-03,  1.38086579e-02,  1.10768968e-03,\n",
       "          2.40147902e-03],\n",
       "        [-4.86911847e-03, -1.13044741e-02, -1.72775112e-03,\n",
       "         -1.24379520e-03, -1.16096476e-02, -1.46665273e-02,\n",
       "         -1.01468330e-02,  8.87030758e-04,  8.82092669e-03,\n",
       "          4.15573968e-03],\n",
       "        [ 1.52555396e-02, -1.81537076e-04, -5.68427057e-03,\n",
       "         -1.28755141e-02, -2.04112479e-05,  2.15418362e-02,\n",
       "         -1.46674398e-02,  1.62050273e-02,  1.18768192e-03,\n",
       "          1.18324361e-03],\n",
       "        [ 1.34781428e-02, -1.24478375e-02, -7.09470606e-04,\n",
       "          4.49040326e-03, -3.73878738e-03,  1.40029440e-02,\n",
       "          6.34708106e-04,  1.05350252e-02, -9.31940482e-03,\n",
       "          5.87946740e-04],\n",
       "        [-1.34302339e-02, -7.04214598e-04,  8.52506709e-03,\n",
       "          1.22252950e-03,  7.51558940e-03, -1.09087465e-02,\n",
       "         -2.06364108e-02,  6.24416154e-03, -2.33196186e-03,\n",
       "         -6.99320483e-03],\n",
       "        [ 1.20010917e-04, -1.42509765e-02,  2.98755298e-03,\n",
       "         -1.40034459e-02, -1.56040159e-02, -2.49629388e-03,\n",
       "         -1.12466556e-02,  1.52089752e-03,  1.03485052e-02,\n",
       "          2.05484996e-02],\n",
       "        [-4.77820475e-03,  6.06629636e-03, -1.00858818e-02,\n",
       "          2.14081931e-05, -1.23727076e-02, -6.83072185e-03,\n",
       "         -7.15824531e-03, -2.88617109e-03, -7.96524613e-03,\n",
       "          8.73467081e-03],\n",
       "        [-1.95586264e-03, -4.70081038e-03,  7.55949840e-03,\n",
       "          6.49240133e-03, -3.16717944e-03, -2.44957252e-03,\n",
       "          1.13236229e-02, -1.09182243e-02,  1.34574920e-03,\n",
       "          7.37690835e-04],\n",
       "        [ 1.76239197e-02,  8.82496439e-04,  1.67471975e-03,\n",
       "          3.67427612e-03,  5.58204302e-03,  7.86332952e-03,\n",
       "          1.08509604e-02,  1.74025435e-03, -8.35268570e-03,\n",
       "         -6.86996087e-03],\n",
       "        [ 8.84733038e-03,  1.38241666e-02,  6.50190936e-03,\n",
       "          8.02624702e-03,  1.50494378e-03,  1.69263653e-03,\n",
       "         -1.16582010e-02, -1.12949339e-02, -2.07634095e-02,\n",
       "          4.29639825e-03],\n",
       "        [ 7.76327650e-03, -1.46007710e-02,  2.12651889e-03,\n",
       "         -1.22045724e-05, -7.05054129e-04, -8.45606849e-03,\n",
       "         -4.80600831e-03,  2.18398867e-02, -5.16633724e-03,\n",
       "          9.19160898e-03],\n",
       "        [ 1.10968000e-02,  1.15710611e-02, -1.42515013e-02,\n",
       "         -7.80671118e-03,  1.52138493e-03, -3.41867565e-03,\n",
       "          2.34201677e-03,  1.25181984e-03, -8.17494790e-03,\n",
       "         -1.09682400e-02],\n",
       "        [-5.09026692e-03,  7.11152069e-03,  9.39700911e-03,\n",
       "          7.55055831e-03, -3.79045221e-03,  1.04109096e-02,\n",
       "         -2.78866664e-03, -1.83597919e-04, -4.34619530e-03,\n",
       "         -2.45026003e-03],\n",
       "        [-8.26705089e-03,  8.40665899e-04, -8.58221612e-03,\n",
       "         -2.11266609e-02, -6.70917416e-03, -4.69589045e-03,\n",
       "          3.29016401e-03, -3.42098315e-03, -4.86083127e-03,\n",
       "         -7.33428442e-03],\n",
       "        [ 2.95277150e-03,  1.10044970e-02, -1.12488547e-02,\n",
       "          1.69146470e-02,  1.38352422e-02,  1.10193748e-02,\n",
       "         -3.63040406e-04, -2.50614017e-03,  3.74596200e-03,\n",
       "          2.37268362e-03],\n",
       "        [-8.15865202e-03,  3.56309791e-03, -9.06153584e-03,\n",
       "         -2.20429088e-03, -1.78285381e-03, -1.90612478e-02,\n",
       "          1.21703089e-02, -2.35800687e-03,  6.28691424e-03,\n",
       "          6.81259745e-03],\n",
       "        [-9.24877996e-03, -1.18412842e-02,  8.24221351e-04,\n",
       "          4.50425600e-03,  7.87579739e-03,  1.98642121e-03,\n",
       "         -1.26261269e-02,  2.61288137e-02,  2.60073376e-03,\n",
       "         -1.65337600e-02],\n",
       "        [ 1.68685780e-02, -1.77784494e-02,  4.79198742e-03,\n",
       "         -5.48894296e-03, -3.32239693e-03, -7.34734723e-03,\n",
       "         -2.01922318e-03, -1.28580621e-02,  1.34678835e-02,\n",
       "          8.90039635e-04],\n",
       "        [-1.36361239e-02,  1.11534381e-02, -2.13691365e-03,\n",
       "          2.62038341e-03,  9.56219245e-03,  1.20604779e-02,\n",
       "         -9.56736657e-03,  8.61056660e-03, -1.10820363e-02,\n",
       "         -1.35296997e-02],\n",
       "        [-5.46385073e-04, -6.25843731e-03, -1.56095351e-03,\n",
       "         -3.38229917e-03, -2.41906282e-03, -2.76346685e-03,\n",
       "         -2.43174730e-03,  1.84103695e-02, -1.41013523e-02,\n",
       "         -8.01977855e-03],\n",
       "        [-1.75117593e-02, -1.60446586e-02, -1.12052572e-02,\n",
       "         -4.06906165e-03, -2.00086299e-02, -2.66282048e-02,\n",
       "          5.69774668e-03,  6.55513443e-03, -1.47779720e-02,\n",
       "          1.44855827e-02],\n",
       "        [ 1.37514251e-02,  2.25064543e-04, -2.43399751e-03,\n",
       "          1.42910986e-02, -1.15057574e-02, -1.52631455e-02,\n",
       "          1.77862957e-02,  1.64121328e-02,  5.92260881e-03,\n",
       "         -2.36573430e-02],\n",
       "        [-2.36819280e-03,  9.19022751e-03,  1.60343003e-02,\n",
       "         -3.60444652e-03, -5.46787406e-03,  1.36056354e-02,\n",
       "         -5.28754400e-03, -6.97042411e-03, -1.40267340e-03,\n",
       "          2.86958140e-03],\n",
       "        [-1.13404170e-03, -5.38141689e-03,  9.49231790e-03,\n",
       "         -1.22774916e-03, -6.27579441e-03, -3.34121820e-03,\n",
       "         -9.26217555e-03, -2.69784477e-03, -9.40639119e-05,\n",
       "         -1.19707528e-03],\n",
       "        [ 1.51299683e-02,  1.08240355e-03, -1.10055750e-03,\n",
       "          1.02829321e-02, -1.28705598e-03, -3.18167242e-03,\n",
       "         -2.62988957e-03, -9.39027435e-03,  2.00263898e-03,\n",
       "         -4.74499807e-03],\n",
       "        [-7.56474299e-03,  1.27116038e-02,  2.95395665e-02,\n",
       "         -1.84716943e-05, -5.11490808e-04, -9.88500849e-03,\n",
       "         -4.95936491e-03, -1.08894195e-02, -7.35156337e-03,\n",
       "          2.66871359e-03]]),\n",
       " 'b2': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10 #10000\n",
    "train_size = x_train[:100].shape[0]\n",
    "batch_size = 2 #100\n",
    "lr = 0.1\n",
    "\n",
    "iter_per_ecoph = max(train_size/batch_size, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_accs = []\n",
    "test_accs = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test_acc : 0.11236666666666667, 0.1135\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m x_batch \u001b[38;5;241m=\u001b[39m x_train[batch_mask]\n\u001b[1;32m      4\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m y_train[batch_mask]\n\u001b[0;32m----> 6\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumerical_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb2\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      9\u001b[0m     network\u001b[38;5;241m.\u001b[39mparams[key] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m lr\u001b[38;5;241m*\u001b[39mgrads[key]\n",
      "File \u001b[0;32m~/Documents/ece5831-2024-code/06/two_layer_net.py:70\u001b[0m, in \u001b[0;36mTwoLayerNet.numerical_gradient\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     67\u001b[0m loss_w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m w: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, y)\n\u001b[1;32m     69\u001b[0m grads \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 70\u001b[0m grads[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numerical_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m grads[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numerical_gradient(loss_w, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     72\u001b[0m grads[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numerical_gradient(loss_w, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw2\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/ece5831-2024-code/06/two_layer_net.py:54\u001b[0m, in \u001b[0;36mTwoLayerNet._numerical_gradient\u001b[0;34m(self, f, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m tmp_val \u001b[38;5;241m=\u001b[39m x[idx]\n\u001b[1;32m     53\u001b[0m x[idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(tmp_val) \u001b[38;5;241m+\u001b[39m h\n\u001b[0;32m---> 54\u001b[0m fxh1 \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# f(x+h)\u001b[39;00m\n\u001b[1;32m     56\u001b[0m x[idx] \u001b[38;5;241m=\u001b[39m tmp_val \u001b[38;5;241m-\u001b[39m h \n\u001b[1;32m     57\u001b[0m fxh2 \u001b[38;5;241m=\u001b[39m f(x) \u001b[38;5;66;03m# f(x-h)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ece5831-2024-code/06/two_layer_net.py:67\u001b[0m, in \u001b[0;36mTwoLayerNet.numerical_gradient.<locals>.<lambda>\u001b[0;34m(w)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumerical_gradient\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y):\n\u001b[0;32m---> 67\u001b[0m     loss_w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m w: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     grads \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     70\u001b[0m     grads[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numerical_gradient(loss_w, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/ece5831-2024-code/06/two_layer_net.py:31\u001b[0m, in \u001b[0;36mTwoLayerNet.loss\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y):\n\u001b[0;32m---> 31\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mcross_entropy_error(y_hat, y)\n",
      "File \u001b[0;32m~/Documents/ece5831-2024-code/06/two_layer_net.py:23\u001b[0m, in \u001b[0;36mTwoLayerNet.predict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m w1, w2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw1\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw2\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     21\u001b[0m b1, b2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb1\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb2\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 23\u001b[0m a1 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m b1\n\u001b[1;32m     24\u001b[0m z1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivations\u001b[38;5;241m.\u001b[39msigmoid(a1)\n\u001b[1;32m     25\u001b[0m a2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(z1, w2) \u001b[38;5;241m+\u001b[39m b2\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(iterations):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    y_batch = y_train[batch_mask]\n",
    "\n",
    "    grads = network.numerical_gradient(x_batch, y_batch)\n",
    "\n",
    "    for key in ('w1', 'b1', 'w2', 'b2'):\n",
    "        network.params[key] -= lr*grads[key]\n",
    "\n",
    "    ## this is for plotting losses over time\n",
    "    train_losses.append(network.loss(x_batch, y_batch))\n",
    "\n",
    "    if i%iter_per_ecoph == 0:\n",
    "        train_acc = network.accuracy(x_train, y_train)\n",
    "        train_accs.append(train_acc)\n",
    "        test_acc = network.accuracy(x_test, y_test)\n",
    "        test_accs.append(test_acc)\n",
    "        print(f'train acc, test_acc : {train_acc}, {test_acc}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_accs))\n",
    "plt.plot(x, train_accs, label='train acc')\n",
    "plt.plot(x, test_accs, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "\n",
    "        return dx\n",
    "\n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "        self.activations = Activations()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.activations.sigmoid(x)\n",
    "        self.out = out\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "\n",
    "        return dx\n",
    "\n",
    "\n",
    "class Affine:\n",
    "    def __init__(self, w, b):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        \n",
    "        self.x = None\n",
    "        self.original_x_shape = None\n",
    "\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # \n",
    "        self.original_x_shape = x.shape\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        self.x = x\n",
    "\n",
    "        out = np.dot(self.x, self.w) + self.b\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.w.T)\n",
    "        self.dw = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        dx = dx.reshape(*self.original_x_shape)  \n",
    "        return dx\n",
    "\n",
    "\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None \n",
    "        self.y_hat = None    \n",
    "        self.y = None    \n",
    "        self.activations = Activations()\n",
    "        self.errors = Errors()\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        self.y = y\n",
    "        self.y_hat = self.activations.softmax(x)\n",
    "        self.loss = self.errors.cross_entropy_error(self.y_hat, self.y)\n",
    "        \n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.y.shape[0]\n",
    "        #if self.y.size == self.y_hat.size: # one hot encoding\n",
    "        \n",
    "        dx = (self.y_hat - self.y) / batch_size\n",
    "        \n",
    "        \"\"\"\n",
    "        else:\n",
    "            dx = self.y_hat.copy()\n",
    "            dx[np.arange(batch_size), self.t] -= 1\n",
    "            dx = dx / batch_size\n",
    "        \"\"\"\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Layer Net with Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from activations import Activations\n",
    "from errors import Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNetWithBackProp:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        self.params = {}\n",
    "\n",
    "        self.params['w1'] = weight_init_std*np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "\n",
    "        self.params['w2'] = weight_init_std*np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "        self.activations = Activations()\n",
    "        self.errors = Errors()\n",
    "\n",
    "        # add layers\n",
    "        self.layers = OrderedDict()\n",
    "        self.update_layers()\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "\n",
    "    def update_layers(self):\n",
    "        self.layers['Affine1'] = Affine(self.params['w1'], self.params['b1'])\n",
    "        self.layers['Rele1'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['w2'], self.params['b2'])\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        ## new implementation for backprop\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        y = x\n",
    "        return y\n",
    "    \n",
    "    def loss(self, x, y):\n",
    "        y_hat = self.predict(x)\n",
    "\n",
    "        # return self.errors.cross_entropy_error(y_hat, y)\n",
    "        return self.last_layer.forward(y_hat, y)\n",
    "\n",
    "    def accuracy(self, x, y):\n",
    "        y_hat = self.predict(x)\n",
    "        p = np.argmax(y_hat, axis=1)\n",
    "        y_p = np.argmax(y, axis=1)\n",
    "\n",
    "        return np.sum(p == y_p)/float(x.shape[0])\n",
    "    \n",
    "\n",
    "    def gradient(self, x, y):\n",
    "        self.loss(x, y)\n",
    "\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        grads = {}\n",
    "        grads['w1'] = self.layers['Affine1'].dw\n",
    "        grads['b1'] = self.layers['Affine1'].db\n",
    "        grads['w2'] = self.layers['Affine2'].dw\n",
    "        grads['b2'] = self.layers['Affine2'].db\n",
    "      \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import Mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: train-images-idx3-ubyte.gz already exists.\n",
      "File: train-labels-idx1-ubyte.gz already exists.\n",
      "File: t10k-images-idx3-ubyte.gz already exists.\n",
      "File: t10k-labels-idx1-ubyte.gz already exists.\n",
      "Pickle: dataset/mnist.pkl already exists.\n",
      "Loading...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "mnist = Mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = TwoLayerNetWithBackProp(input_size=28*28, hidden_size=100, output_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "lr = 0.1\n",
    "\n",
    "iter_per_ecoph = max(train_size/batch_size, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_accs = []\n",
    "test_accs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test_acc : 0.16175, 0.1613\n",
      "train acc, test_acc : 0.9056833333333333, 0.9113\n",
      "train acc, test_acc : 0.9257833333333333, 0.9269\n",
      "train acc, test_acc : 0.9396666666666667, 0.9374\n",
      "train acc, test_acc : 0.9482833333333334, 0.9462\n",
      "train acc, test_acc : 0.9549333333333333, 0.9526\n",
      "train acc, test_acc : 0.9605166666666667, 0.9569\n",
      "train acc, test_acc : 0.9647833333333333, 0.9592\n",
      "train acc, test_acc : 0.9683, 0.9632\n",
      "train acc, test_acc : 0.9696833333333333, 0.9659\n",
      "train acc, test_acc : 0.9724333333333334, 0.968\n",
      "train acc, test_acc : 0.97555, 0.9717\n",
      "train acc, test_acc : 0.9776666666666667, 0.972\n",
      "train acc, test_acc : 0.9792166666666666, 0.9736\n",
      "train acc, test_acc : 0.98005, 0.9738\n",
      "train acc, test_acc : 0.9816333333333334, 0.973\n",
      "train acc, test_acc : 0.9835833333333334, 0.9749\n"
     ]
    }
   ],
   "source": [
    "for i in range(iterations):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    y_batch = y_train[batch_mask]\n",
    "\n",
    "    grads = network.gradient(x_batch, y_batch)\n",
    "\n",
    "    for key in ('w1', 'b1', 'w2', 'b2'):\n",
    "        network.params[key] -= lr*grads[key]\n",
    "\n",
    "    ## this is for plotting losses over time\n",
    "    train_losses.append(network.loss(x_batch, y_batch))\n",
    "\n",
    "    if i%iter_per_ecoph == 0:\n",
    "        train_acc = network.accuracy(x_train, y_train)\n",
    "        train_accs.append(train_acc)\n",
    "        test_acc = network.accuracy(x_test, y_test)\n",
    "        test_accs.append(test_acc)\n",
    "        print(f'train acc, test_acc : {train_acc}, {test_acc}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_accs))\n",
    "plt.plot(x, train_accs, label='train acc')\n",
    "plt.plot(x, test_accs, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "my_weight_pkl_file = 'jaerock_weights.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle: jaerock_weights.pkl is being created.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open(f'{my_weight_pkl_file}', 'wb') as f:\n",
    "    print(f'Pickle: {my_weight_pkl_file} is being created.')\n",
    "    pickle.dump(network.params, f)\n",
    "    print('Done.') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.params = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using your own TwoLayerNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = TwoLayerNetWithBackProp(input_size=28*28, hidden_size=100, output_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{my_weight_pkl_file}', 'rb') as f:\n",
    "    network.params = pickle.load(f)\n",
    "\n",
    "network.update_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import Mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: train-images-idx3-ubyte.gz already exists.\n",
      "File: train-labels-idx1-ubyte.gz already exists.\n",
      "File: t10k-images-idx3-ubyte.gz already exists.\n",
      "File: t10k-labels-idx1-ubyte.gz already exists.\n",
      "Pickle: dataset/mnist.pkl already exists.\n",
      "Loading...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "mnist = Mnist()\n",
    "(_, _), (x_test, y_test) = mnist.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = network.predict(x_test[0:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7add1007ec80>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[10].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.53958264, -6.30247869,  3.96667689, -2.86688026, -7.46816745,\n",
       "        1.39351808,  1.00439998, -0.74908079, -1.66393792,  0.62830638])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.53958264, -6.30247869,  3.96667689, -2.86688026, -7.46816745,\n",
       "        1.39351808,  1.00439998, -0.74908079, -1.66393792,  0.62830638])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_hat[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_test[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece5831-2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
